{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n# machine learning packages\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\n\n# nlp packages\n!pip install -q --upgrade transformers\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, DataCollatorWithPadding, TrainingArguments\nfrom datasets import Dataset\ntransformers.logging.set_verbosity_info()\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:10:34.841039Z","iopub.execute_input":"2025-10-23T01:10:34.841400Z","iopub.status.idle":"2025-10-23T01:11:34.997099Z","shell.execute_reply.started":"2025-10-23T01:10:34.841368Z","shell.execute_reply":"2025-10-23T01:11:34.996039Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2025-10-23 01:11:13.813799: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761181874.099312      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761181874.193258      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# check python package versions\n\nprint('numpy version is: {}'.format(np.__version__))\nprint('pandas version is: {}'.format(pd.__version__))\nprint('matplotlib version is: {}'.format(matplotlib.__version__))\nprint('scikit-learn version is: {}'.format(sklearn.__version__))\nprint('transformers version is: {}'.format(transformers.__version__))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:11:34.998786Z","iopub.execute_input":"2025-10-23T01:11:34.999535Z","iopub.status.idle":"2025-10-23T01:11:35.006791Z","shell.execute_reply.started":"2025-10-23T01:11:34.999507Z","shell.execute_reply":"2025-10-23T01:11:35.005746Z"}},"outputs":[{"name":"stdout","text":"numpy version is: 1.26.4\npandas version is: 2.2.3\nmatplotlib version is: 3.7.2\nscikit-learn version is: 1.2.2\ntransformers version is: 4.57.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# load in the training data\ntrain_df= pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\n\n# look at first 5 rows\nprint(train_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:11:35.007713Z","iopub.execute_input":"2025-10-23T01:11:35.008031Z","iopub.status.idle":"2025-10-23T01:11:35.110780Z","shell.execute_reply.started":"2025-10-23T01:11:35.007999Z","shell.execute_reply":"2025-10-23T01:11:35.109779Z"}},"outputs":[{"name":"stdout","text":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# check nulls and column types for training data\ntrain_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:11:35.112491Z","iopub.execute_input":"2025-10-23T01:11:35.112833Z","iopub.status.idle":"2025-10-23T01:11:35.144070Z","shell.execute_reply.started":"2025-10-23T01:11:35.112799Z","shell.execute_reply":"2025-10-23T01:11:35.142878Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7613 entries, 0 to 7612\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   id        7613 non-null   int64 \n 1   keyword   7552 non-null   object\n 2   location  5080 non-null   object\n 3   text      7613 non-null   object\n 4   target    7613 non-null   int64 \ndtypes: int64(2), object(3)\nmemory usage: 297.5+ KB\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# look at the training target\ncount1= train_df['target'].value_counts()\nlabel1= [0, 1]\n\n# visualize label distribution\nfig1= plt.figure(figsize= (6, 6))\nax1= plt.gca()\nax1.bar(['Safe', 'Disaster'], count1.values.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:11:35.145395Z","iopub.execute_input":"2025-10-23T01:11:35.145797Z","iopub.status.idle":"2025-10-23T01:11:35.374829Z","shell.execute_reply.started":"2025-10-23T01:11:35.145761Z","shell.execute_reply":"2025-10-23T01:11:35.373927Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<BarContainer object of 2 artists>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"Dataset is balanced.","metadata":{}},{"cell_type":"code","source":"# load in the test data\ntest_df= pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\n\n# look at first 5 rows of test dataframe\nprint(test_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:11:35.375790Z","iopub.execute_input":"2025-10-23T01:11:35.376126Z","iopub.status.idle":"2025-10-23T01:11:35.406831Z","shell.execute_reply.started":"2025-10-23T01:11:35.376097Z","shell.execute_reply":"2025-10-23T01:11:35.405681Z"}},"outputs":[{"name":"stdout","text":"   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# remove extra columns\ntrain1= train_df.loc[:, ['text', 'target']]\ntrain1.columns= ['text', 'label']\ntest_id= test_df.loc[:, 'id'].to_frame()\ntest1= test_df.loc[:, 'text'].to_frame()\n\n# look at new training dataframe\nprint('training data')\nprint(train1.head())\nprint(train1.shape)\n\n# look at test id series\nprint('-'*80)\nprint('test id')\nprint(test_id.head())\n\n# look at new test dataframe\nprint('-'*80)\nprint('test data')\nprint(test1.head())\nprint(test1.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:11:35.407956Z","iopub.execute_input":"2025-10-23T01:11:35.408331Z","iopub.status.idle":"2025-10-23T01:11:35.427003Z","shell.execute_reply.started":"2025-10-23T01:11:35.408297Z","shell.execute_reply":"2025-10-23T01:11:35.425814Z"}},"outputs":[{"name":"stdout","text":"training data\n                                                text  label\n0  Our Deeds are the Reason of this #earthquake M...      1\n1             Forest fire near La Ronge Sask. Canada      1\n2  All residents asked to 'shelter in place' are ...      1\n3  13,000 people receive #wildfires evacuation or...      1\n4  Just got sent this photo from Ruby #Alaska as ...      1\n(7613, 2)\n--------------------------------------------------------------------------------\ntest id\n   id\n0   0\n1   2\n2   3\n3   9\n4  11\n--------------------------------------------------------------------------------\ntest data\n                                                text\n0                 Just happened a terrible car crash\n1  Heard about #earthquake is different cities, s...\n2  there is a forest fire at spot pond, geese are...\n3           Apocalypse lighting. #Spokane #wildfires\n4      Typhoon Soudelor kills 28 in China and Taiwan\n(3263, 1)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# split training into training and validation\n\ntrain2, val2= train_test_split(train1, test_size= 0.2, shuffle= True, random_state= 24)\n\n# reset index for training and test\ntrain2.reset_index(drop= True, inplace= True)\nval2.reset_index(drop= True, inplace= True)\n\n# look at training dataframe after split\nprint('training data')\nprint(train2.head())\nprint(train2.shape)\n\n# look at validation dataframe\nprint('\\n validation data')\nprint(val2.head())\nprint(val2.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:11:56.749717Z","iopub.execute_input":"2025-10-23T01:11:56.750056Z","iopub.status.idle":"2025-10-23T01:11:56.765135Z","shell.execute_reply.started":"2025-10-23T01:11:56.750033Z","shell.execute_reply":"2025-10-23T01:11:56.763723Z"}},"outputs":[{"name":"stdout","text":"training data\n                                                text  label\n0  @cnni @PrisonPlanet Climate Change CNN weather...      1\n1  Refugee Connections Indiegogo campaign will be...      1\n2  Want to work in #Tarzana CA? View our latest o...      0\n3  Slow clap for this pilot. Dramatic Video Shows...      1\n4  Learn How I Gained Access To The Secrets Of Th...      0\n(6090, 2)\n\n validation data\n                                                text  label\n0  Kids got Disney version of the game Operation ...      0\n1  UPDATE: Indiana State Police reopening I-65 ne...      1\n2  God forbid anyone in my family knows how to an...      0\n3  First wreck today. So so glad me and mom are o...      0\n4  Exploration takes seismic shift in Gabon to So...      0\n(1523, 2)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# convert from dataframe to dataset\n\n# training\ntrain_data= Dataset.from_pandas(train2)\nprint('training')\nprint(train_data.features)\n\n# validation\nval_data= Dataset.from_pandas(val2)\nprint('validation')\nprint(val_data.features)\n\n# test\ntest_data= Dataset.from_pandas(test1)\nprint('test')\nprint(test_data.features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:12:04.295451Z","iopub.execute_input":"2025-10-23T01:12:04.295863Z","iopub.status.idle":"2025-10-23T01:12:04.343401Z","shell.execute_reply.started":"2025-10-23T01:12:04.295832Z","shell.execute_reply":"2025-10-23T01:12:04.342241Z"}},"outputs":[{"name":"stdout","text":"training\n{'text': Value('string'), 'label': Value('int64')}\nvalidation\n{'text': Value('string'), 'label': Value('int64')}\ntest\n{'text': Value('string')}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# model distilbert\ndbert= 'distilbert/distilbert-base-uncased'\n\n# initialize model tokenizer\ntokenizer= AutoTokenizer.from_pretrained(dbert)\n\nid2label= {0: 'safe', 1:'disaster'}\nlabel2id= {'safe':0, 'disaster':1}\n\n# setup model\nmodel= AutoModelForSequenceClassification.from_pretrained(dbert, num_labels= 2, \n                                                          id2label= id2label, label2id= label2id)\n\n# freeze model layers (not classification head)\nfor name, param in model.named_parameters():\n    if 'distilbert' in name:\n        param.requires_grad= False\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:12:26.629436Z","iopub.execute_input":"2025-10-23T01:12:26.629913Z","iopub.status.idle":"2025-10-23T01:12:30.763296Z","shell.execute_reply.started":"2025-10-23T01:12:26.629881Z","shell.execute_reply":"2025-10-23T01:12:30.761795Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4260ef7f10834a919409d04696d3df65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07c55367e550489ea9fe18f612b604df"}},"metadata":{}},{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\nModel config DistilBertConfig {\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForMaskedLM\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"initializer_range\": 0.02,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.57.1\",\n  \"vocab_size\": 30522\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80efcfa08ab5455ab2228a230a6b8636"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31198d3fb0fc4c1bac61cb711de9d125"}},"metadata":{}},{"name":"stderr","text":"loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/vocab.txt\nloading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/tokenizer.json\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at None\nloading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/tokenizer_config.json\nloading file chat_template.jinja from cache at None\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\nModel config DistilBertConfig {\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForMaskedLM\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"initializer_range\": 0.02,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.57.1\",\n  \"vocab_size\": 30522\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\nModel config DistilBertConfig {\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForMaskedLM\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"id2label\": {\n    \"0\": \"safe\",\n    \"1\": \"disaster\"\n  },\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"disaster\": 1,\n    \"safe\": 0\n  },\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.57.1\",\n  \"vocab_size\": 30522\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbaa8a4dd1ff4b5086f3d4af7d97e7e9"}},"metadata":{}},{"name":"stderr","text":"loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/model.safetensors\nSome weights of the model checkpoint at distilbert/distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# tokenize datasets\n\n# tokenize function\ndef token_fn(sentence1):\n    return tokenizer(sentence1['text'], truncation= True)\n\n# tokenize training\ntrain_token= train_data.map(token_fn, batched= True)\n\n\n# tokenize validation\nval_token= val_data.map(token_fn, batched= True)\n\n\n# tokenize test\ntest_token= test_data.map(token_fn, batched= True)\n\n# look at training tokenized\nprint('training tokenized')\nprint(train_token.features)\n\n# look at validation tokenized\nprint('validation tokenized')\nprint(val_token.features)\n\n# look at test tokenized\nprint('test tokenized')\nprint(test_token.features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:12:52.735272Z","iopub.execute_input":"2025-10-23T01:12:52.736297Z","iopub.status.idle":"2025-10-23T01:12:54.321750Z","shell.execute_reply.started":"2025-10-23T01:12:52.736248Z","shell.execute_reply":"2025-10-23T01:12:54.320451Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6090 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a984e1a8dfc4b2493e7f5ba55af8e20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1523 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2331dea720b64a67a49dc5c917292840"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3263 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"072543b4baca4470b41bfe40ac84d008"}},"metadata":{}},{"name":"stdout","text":"training tokenized\n{'text': Value('string'), 'label': Value('int64'), 'input_ids': List(Value('int32')), 'attention_mask': List(Value('int8'))}\nvalidation tokenized\n{'text': Value('string'), 'label': Value('int64'), 'input_ids': List(Value('int32')), 'attention_mask': List(Value('int8'))}\ntest tokenized\n{'text': Value('string'), 'input_ids': List(Value('int32')), 'attention_mask': List(Value('int8'))}\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# data collator to pad the batches\ncollator= DataCollatorWithPadding(tokenizer= tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:13:11.538613Z","iopub.execute_input":"2025-10-23T01:13:11.539041Z","iopub.status.idle":"2025-10-23T01:13:11.546870Z","shell.execute_reply.started":"2025-10-23T01:13:11.539009Z","shell.execute_reply":"2025-10-23T01:13:11.545787Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# function to compute metrics\n\ndef metric_fn(eval_preds):\n    # extract prediction and labels\n    preds, labels= eval_preds\n    # get prediction\n    y_pred= np.argmax(preds, axis= 1)\n    # accuracy score\n    acc1= accuracy_score(labels, y_pred)\n    # f1 score\n    f1= f1_score(labels, y_pred)\n    print('accuracy is:{} and f1 score is:{}'.format(acc1, f1))\n    return {'accuracy': acc1, 'f1':f1}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:14:23.686833Z","iopub.execute_input":"2025-10-23T01:14:23.687893Z","iopub.status.idle":"2025-10-23T01:14:23.694066Z","shell.execute_reply.started":"2025-10-23T01:14:23.687854Z","shell.execute_reply":"2025-10-23T01:14:23.693035Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# training arguments\n# learning rate\nrate1= 5e-4\n# batch size\nbatch1= 10\n# num epochs\nepoch1= 10\n\ntraining_args= TrainingArguments(output_dir= '/kaggle/working/', \n                                learning_rate= rate1, \n                                report_to= 'none',\n                                per_device_train_batch_size= batch1,\n                                per_device_eval_batch_size= batch1,\n                                num_train_epochs= epoch1,\n                                weight_decay= 0.1,\n                                metric_for_best_model= 'f1',\n                                logging_strategy= 'epoch', \n                                fp16= True,\n                                eval_strategy= 'epoch', \n                                save_strategy= 'epoch',\n                                load_best_model_at_end= True) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:14:53.614968Z","iopub.execute_input":"2025-10-23T01:14:53.615915Z","iopub.status.idle":"2025-10-23T01:14:53.628000Z","shell.execute_reply.started":"2025-10-23T01:14:53.615885Z","shell.execute_reply":"2025-10-23T01:14:53.626778Z"}},"outputs":[{"name":"stderr","text":"PyTorch: setting up devices\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# setup trainer\n\ntrainer= Trainer(model= model, args= training_args, train_dataset= train_token, \n                 eval_dataset= val_token, tokenizer= tokenizer, data_collator= collator, \n                 compute_metrics= metric_fn)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T01:15:13.276224Z","iopub.execute_input":"2025-10-23T01:15:13.276619Z","iopub.status.idle":"2025-10-23T02:07:32.331310Z","shell.execute_reply.started":"2025-10-23T01:15:13.276591Z","shell.execute_reply":"2025-10-23T02:07:32.330159Z"}},"outputs":[{"name":"stderr","text":"Using auto half precision backend\nThe following columns in the Training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 6,090\n  Num Epochs = 10\n  Instantaneous batch size per device = 10\n  Total train batch size (w. parallel, distributed & accumulation) = 10\n  Gradient Accumulation steps = 1\n  Total optimization steps = 6,090\n  Number of trainable parameters = 592,130\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6090' max='6090' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6090/6090 52:17, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.471500</td>\n      <td>0.456822</td>\n      <td>0.805647</td>\n      <td>0.732369</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.453300</td>\n      <td>0.410743</td>\n      <td>0.819435</td>\n      <td>0.771405</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.435600</td>\n      <td>0.414689</td>\n      <td>0.826658</td>\n      <td>0.786753</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.429400</td>\n      <td>0.409596</td>\n      <td>0.820092</td>\n      <td>0.780096</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.424700</td>\n      <td>0.464050</td>\n      <td>0.780696</td>\n      <td>0.764124</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.415300</td>\n      <td>0.410657</td>\n      <td>0.822718</td>\n      <td>0.781906</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.407300</td>\n      <td>0.408754</td>\n      <td>0.827315</td>\n      <td>0.777684</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.398100</td>\n      <td>0.407658</td>\n      <td>0.825345</td>\n      <td>0.772260</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.397700</td>\n      <td>0.408043</td>\n      <td>0.826658</td>\n      <td>0.785016</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.390700</td>\n      <td>0.407183</td>\n      <td>0.827315</td>\n      <td>0.787732</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1523\n  Batch size = 10\n","output_type":"stream"},{"name":"stdout","text":"accuracy is:0.8056467498358503 and f1 score is:0.7323688969258589\n","output_type":"stream"},{"name":"stderr","text":"Saving model checkpoint to /kaggle/working/checkpoint-609\nConfiguration saved in /kaggle/working/checkpoint-609/config.json\nModel weights saved in /kaggle/working/checkpoint-609/model.safetensors\ntokenizer config file saved in /kaggle/working/checkpoint-609/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-609/special_tokens_map.json\nThe following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1523\n  Batch size = 10\n","output_type":"stream"},{"name":"stdout","text":"accuracy is:0.8194353250164149 and f1 score is:0.771404821280133\n","output_type":"stream"},{"name":"stderr","text":"Saving model checkpoint to /kaggle/working/checkpoint-1218\nConfiguration saved in /kaggle/working/checkpoint-1218/config.json\nModel weights saved in /kaggle/working/checkpoint-1218/model.safetensors\ntokenizer config file saved in /kaggle/working/checkpoint-1218/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-1218/special_tokens_map.json\nThe following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1523\n  Batch size = 10\n","output_type":"stream"},{"name":"stdout","text":"accuracy is:0.8266579120157583 and f1 score is:0.7867528271405493\n","output_type":"stream"},{"name":"stderr","text":"Saving model checkpoint to /kaggle/working/checkpoint-1827\nConfiguration saved in /kaggle/working/checkpoint-1827/config.json\nModel weights saved in /kaggle/working/checkpoint-1827/model.safetensors\ntokenizer config file saved in /kaggle/working/checkpoint-1827/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-1827/special_tokens_map.json\nThe following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1523\n  Batch size = 10\n","output_type":"stream"},{"name":"stdout","text":"accuracy is:0.8200919238345371 and f1 score is:0.7800963081861958\n","output_type":"stream"},{"name":"stderr","text":"Saving model checkpoint to /kaggle/working/checkpoint-2436\nConfiguration saved in /kaggle/working/checkpoint-2436/config.json\nModel weights saved in /kaggle/working/checkpoint-2436/model.safetensors\ntokenizer config file saved in /kaggle/working/checkpoint-2436/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-2436/special_tokens_map.json\nThe following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1523\n  Batch size = 10\n","output_type":"stream"},{"name":"stdout","text":"accuracy is:0.7806959947472094 and f1 score is:0.7641242937853108\n","output_type":"stream"},{"name":"stderr","text":"Saving model checkpoint to /kaggle/working/checkpoint-3045\nConfiguration saved in /kaggle/working/checkpoint-3045/config.json\nModel weights saved in /kaggle/working/checkpoint-3045/model.safetensors\ntokenizer config file saved in /kaggle/working/checkpoint-3045/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-3045/special_tokens_map.json\nThe following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1523\n  Batch size = 10\n","output_type":"stream"},{"name":"stdout","text":"accuracy is:0.8227183191070256 and f1 score is:0.7819063004846526\n","output_type":"stream"},{"name":"stderr","text":"Saving model checkpoint to /kaggle/working/checkpoint-3654\nConfiguration saved in /kaggle/working/checkpoint-3654/config.json\nModel weights saved in /kaggle/working/checkpoint-3654/model.safetensors\ntokenizer config file saved in /kaggle/working/checkpoint-3654/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-3654/special_tokens_map.json\nThe following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1523\n  Batch size = 10\n","output_type":"stream"},{"name":"stdout","text":"accuracy is:0.8273145108338805 and f1 score is:0.7776838546069316\n","output_type":"stream"},{"name":"stderr","text":"Saving model checkpoint to /kaggle/working/checkpoint-4263\nConfiguration saved in /kaggle/working/checkpoint-4263/config.json\nModel weights saved in /kaggle/working/checkpoint-4263/model.safetensors\ntokenizer config file saved in /kaggle/working/checkpoint-4263/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-4263/special_tokens_map.json\nThe following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1523\n  Batch size = 10\n","output_type":"stream"},{"name":"stdout","text":"accuracy is:0.8253447143795141 and f1 score is:0.7722602739726027\n","output_type":"stream"},{"name":"stderr","text":"Saving model checkpoint to /kaggle/working/checkpoint-4872\nConfiguration saved in /kaggle/working/checkpoint-4872/config.json\nModel weights saved in /kaggle/working/checkpoint-4872/model.safetensors\ntokenizer config file saved in /kaggle/working/checkpoint-4872/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-4872/special_tokens_map.json\nThe following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1523\n  Batch size = 10\n","output_type":"stream"},{"name":"stdout","text":"accuracy is:0.8266579120157583 and f1 score is:0.785016286644951\n","output_type":"stream"},{"name":"stderr","text":"Saving model checkpoint to /kaggle/working/checkpoint-5481\nConfiguration saved in /kaggle/working/checkpoint-5481/config.json\nModel weights saved in /kaggle/working/checkpoint-5481/model.safetensors\ntokenizer config file saved in /kaggle/working/checkpoint-5481/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-5481/special_tokens_map.json\nThe following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1523\n  Batch size = 10\n","output_type":"stream"},{"name":"stdout","text":"accuracy is:0.8273145108338805 and f1 score is:0.7877320419693301\n","output_type":"stream"},{"name":"stderr","text":"Saving model checkpoint to /kaggle/working/checkpoint-6090\nConfiguration saved in /kaggle/working/checkpoint-6090/config.json\nModel weights saved in /kaggle/working/checkpoint-6090/model.safetensors\ntokenizer config file saved in /kaggle/working/checkpoint-6090/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/checkpoint-6090/special_tokens_map.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from /kaggle/working/checkpoint-6090 (score: 0.7877320419693301).\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=6090, training_loss=0.42236725003848524, metrics={'train_runtime': 3138.3075, 'train_samples_per_second': 19.405, 'train_steps_per_second': 1.941, 'total_flos': 809851860502080.0, 'train_loss': 0.42236725003848524, 'epoch': 10.0})"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"Model from epoch 10 had lowest validation loss, this model was chosen for predictions on test data.","metadata":{}},{"cell_type":"code","source":"# use the model above for prediction on test\n\n# model with lowest validation loss\nsaved_model1= '/kaggle/working/checkpoint-6090/'\n\nmodel1= AutoModelForSequenceClassification.from_pretrained(saved_model1)\n\ntest_args= TrainingArguments(output_dir= '/kaggle/working/', \n                                report_to= 'none',\n                                per_device_eval_batch_size= batch1,\n                                do_train= False, \n                                do_predict= True) \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T02:08:58.475378Z","iopub.execute_input":"2025-10-23T02:08:58.475829Z","iopub.status.idle":"2025-10-23T02:08:58.563289Z","shell.execute_reply.started":"2025-10-23T02:08:58.475800Z","shell.execute_reply":"2025-10-23T02:08:58.561907Z"}},"outputs":[{"name":"stderr","text":"loading configuration file /kaggle/working/checkpoint-6090/config.json\nModel config DistilBertConfig {\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForSequenceClassification\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"dtype\": \"float32\",\n  \"hidden_dim\": 3072,\n  \"id2label\": {\n    \"0\": \"safe\",\n    \"1\": \"disaster\"\n  },\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"disaster\": 1,\n    \"safe\": 0\n  },\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"problem_type\": \"single_label_classification\",\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.57.1\",\n  \"vocab_size\": 30522\n}\n\nloading weights file /kaggle/working/checkpoint-6090/model.safetensors\nPyTorch: setting up devices\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# trainer for batched inference\n\n# trainer to make predictions on batched test data\ntrainer1= Trainer(model= model1, args= test_args, data_collator= collator)\n\n# get prediction results\nresults= trainer1.predict(test_token)\n# get predicted labels\nlogits= results.predictions\ny_test_pred1= np.argmax(logits, axis= 1)\nlabels= results.label_ids\n\n# make dataframe for submission file\ny_test_pred= pd.Series(y_test_pred1, name= 'target')\ny_test= pd.concat([test_id, y_test_pred], axis= 1)\n\n# look at first 5 predictions\nprint('test df')\nprint(y_test.head())\n\n# submit file to competition\nsub_df= y_test.to_csv(\"/kaggle/working/submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T02:09:47.318256Z","iopub.execute_input":"2025-10-23T02:09:47.318624Z","iopub.status.idle":"2025-10-23T02:11:58.911146Z","shell.execute_reply.started":"2025-10-23T02:09:47.318598Z","shell.execute_reply":"2025-10-23T02:11:58.910019Z"}},"outputs":[{"name":"stderr","text":"The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Prediction *****\n  Num examples = 3263\n  Batch size = 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"test df\n   id  target\n0   0       1\n1   2       1\n2   3       1\n3   9       1\n4  11       1\n","output_type":"stream"}],"execution_count":17}]}